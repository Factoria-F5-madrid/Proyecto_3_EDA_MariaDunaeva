{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b5471ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5865135c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 0. CARGA DE DATOS\n",
    "# ========================================\n",
    "\n",
    "def cargar_datos_ciudades():\n",
    "    \"\"\"\n",
    "    Carga el dataset de ciudades tur√≠sticas desde el archivo CSV\n",
    "    \"\"\"\n",
    "    print(\"üìÇ CARGANDO DATASET DE CIUDADES TUR√çSTICAS...\")\n",
    "    \n",
    "    try:\n",
    "        # Intentar cargar desde la carpeta data/raw\n",
    "        df = pd.read_csv('../data/raw/Worldwide Travel Cities Dataset (Ratings and Climate).csv')\n",
    "        print(\"‚úÖ Dataset cargado exitosamente\")\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        try:\n",
    "            # Intentar desde la carpeta actual\n",
    "            df = pd.read_csv('Worldwide Travel Cities Dataset (Ratings and Climate).csv')\n",
    "            print(\"‚úÖ Dataset cargado exitosamente desde carpeta actual\")\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            print(\"‚ö†Ô∏è Archivo CSV no encontrado.\")\n",
    "                \n",
    "    print(f\"üìä Dataset cargado: {df.shape[0]} ciudades, {df.shape[1]} variables\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ded442d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 1. LIMPIEZA ESPEC√çFICA PARA DATASET TUR√çSTICO\n",
    "# ========================================\n",
    "\n",
    "def limpiar_datos_ciudades(df):\n",
    "    \"\"\"\n",
    "    Realiza limpieza espec√≠fica para el dataset de ciudades tur√≠sticas\n",
    "    \"\"\"\n",
    "    print(\"=\"*70)\n",
    "    print(\"üßπ LIMPIEZA DE DATOS - CIUDADES TUR√çSTICAS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    df_limpio = df.copy()\n",
    "    \n",
    "    print(f\"üìä Dataset original: {df_limpio.shape[0]} ciudades, {df_limpio.shape[1]} variables\")\n",
    "     # 1.1 Tratamiento de valores nulos\n",
    "    print(\"\\nüîß TRATAMIENTO DE VALORES NULOS:\")\n",
    "    \n",
    "    nulos_antes = df_limpio.isnull().sum().sum()\n",
    "    \n",
    "    for columna in df_limpio.columns:\n",
    "        nulos_col = df_limpio[columna].isnull().sum()\n",
    "        \n",
    "        if nulos_col > 0:\n",
    "            print(f\"   ‚Ä¢ {columna}: {nulos_col} valores nulos\")\n",
    "            \n",
    "            # Estrategias espec√≠ficas por tipo de variable\n",
    "            if 'Rating' in columna:\n",
    "                # Para ratings: usar mediana por continente si existe, sino mediana general\n",
    "                if 'Continent' in df_limpio.columns:\n",
    "                    df_limpio[columna] = df_limpio.groupby('Continent')[columna].transform(\n",
    "                        lambda x: x.fillna(x.median())\n",
    "                    )\n",
    "                    # Si a√∫n quedan nulos, usar mediana general\n",
    "                    df_limpio[columna].fillna(df_limpio[columna].median(), inplace=True)\n",
    "                else:\n",
    "                    df_limpio[columna].fillna(df_limpio[columna].median(), inplace=True)\n",
    "                print(f\"     ‚Üí Rellenado con mediana por grupo/general\")\n",
    "                \n",
    "            elif columna in ['Average_Temperature', 'Annual_Rainfall', 'Humidity', 'Sunshine_Hours']:\n",
    "                # Para datos clim√°ticos: usar mediana por continente\n",
    "                if 'Continent' in df_limpio.columns:\n",
    "                    df_limpio[columna] = df_limpio.groupby('Continent')[columna].transform(\n",
    "                        lambda x: x.fillna(x.median())\n",
    "                    )\n",
    "                    df_limpio[columna].fillna(df_limpio[columna].median(), inplace=True)\n",
    "                else:\n",
    "                    df_limpio[columna].fillna(df_limpio[columna].median(), inplace=True)\n",
    "                print(f\"     ‚Üí Rellenado con mediana clim√°tica regional\")\n",
    "                \n",
    "            elif df_limpio[columna].dtype in ['int64', 'float64']:\n",
    "                # Otras variables num√©ricas: mediana\n",
    "                mediana = df_limpio[columna].median()\n",
    "                df_limpio[columna].fillna(mediana, inplace=True)\n",
    "                print(f\"     ‚Üí Rellenado con mediana ({mediana:.2f})\")\n",
    "                \n",
    "            else:\n",
    "                # Variables categ√≥ricas: moda\n",
    "                moda = df_limpio[columna].mode()\n",
    "                if len(moda) > 0:\n",
    "                    df_limpio[columna].fillna(moda[0], inplace=True)\n",
    "                    print(f\"     ‚Üí Rellenado con moda ({moda[0]})\")\n",
    "    \n",
    "    nulos_despues = df_limpio.isnull().sum().sum()\n",
    "    print(f\"\\n‚úÖ Valores nulos eliminados: {nulos_antes} ‚Üí {nulos_despues}\")\n",
    "    \n",
    "    # 1.2 Eliminar duplicados\n",
    "    duplicados_antes = len(df_limpio)\n",
    "    \n",
    "    # Duplicados exactos\n",
    "    df_limpio = df_limpio.drop_duplicates()\n",
    "    duplicados_exactos = duplicados_antes - len(df_limpio)\n",
    "    \n",
    "    # Duplicados por ciudad (si existe la columna)\n",
    "    if 'City' in df_limpio.columns:\n",
    "        ciudades_duplicadas_antes = df_limpio['City'].duplicated().sum()\n",
    "        if ciudades_duplicadas_antes > 0:\n",
    "            print(f\"\\n‚ö†Ô∏è Encontradas {ciudades_duplicadas_antes} ciudades duplicadas:\")\n",
    "            duplicadas = df_limpio[df_limpio['City'].duplicated(keep=False)]['City'].value_counts()\n",
    "            for ciudad, count in duplicadas.head().items():\n",
    "                print(f\"   ‚Ä¢ {ciudad}: aparece {count} veces\")\n",
    "            \n",
    "            # Decidir estrategia: mantener la primera ocurrencia\n",
    "            df_limpio = df_limpio.drop_duplicates(subset=['City'], keep='first')\n",
    "            ciudades_eliminadas = ciudades_duplicadas_antes\n",
    "            print(f\"   ‚Üí {ciudades_eliminadas} ciudades duplicadas eliminadas\")\n",
    "    \n",
    "    print(f\"\\nüóëÔ∏è DUPLICADOS ELIMINADOS: {duplicados_exactos} filas exactas\")\n",
    "    \n",
    "    # 1.3 Validar rangos de datos\n",
    "    print(f\"\\n‚úÖ VALIDACI√ìN DE RANGOS:\")\n",
    "    \n",
    "    # Validar ratings (deben estar entre 1-10)\n",
    "    rating_columns = [col for col in df_limpio.columns if 'Rating' in col]\n",
    "    for col in rating_columns:\n",
    "        valores_fuera_rango = len(df_limpio[(df_limpio[col] < 1) | (df_limpio[col] > 10)])\n",
    "        if valores_fuera_rango > 0:\n",
    "            df_limpio[col] = np.clip(df_limpio[col], 1, 10)\n",
    "            print(f\"   ‚Ä¢ {col}: {valores_fuera_rango} valores ajustados al rango [1-10]\")\n",
    "        else:\n",
    "            print(f\"   ‚Ä¢ {col}: ‚úÖ rango v√°lido [1-10]\")\n",
    "    \n",
    "    # Validar temperaturas (rango razonable -50 a +50¬∞C)\n",
    "    if 'Average_Temperature' in df_limpio.columns:\n",
    "        temp_extremas = len(df_limpio[(df_limpio['Average_Temperature'] < -50) | \n",
    "                                     (df_limpio['Average_Temperature'] > 50)])\n",
    "        if temp_extremas > 0:\n",
    "            df_limpio['Average_Temperature'] = np.clip(df_limpio['Average_Temperature'], -50, 50)\n",
    "            print(f\"   ‚Ä¢ Average_Temperature: {temp_extremas} valores extremos ajustados\")\n",
    "    \n",
    "    # Validar humedad (0-100%)\n",
    "    if 'Humidity' in df_limpio.columns:\n",
    "        humidity_fuera = len(df_limpio[(df_limpio['Humidity'] < 0) | (df_limpio['Humidity'] > 100)])\n",
    "        if humidity_fuera > 0:\n",
    "            df_limpio['Humidity'] = np.clip(df_limpio['Humidity'], 0, 100)\n",
    "            print(f\"   ‚Ä¢ Humidity: {humidity_fuera} valores ajustados al rango [0-100]\")\n",
    "    \n",
    "    print(f\"\\nüìä Dataset limpio: {df_limpio.shape[0]} ciudades, {df_limpio.shape[1]} variables\")\n",
    "    return df_limpio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f736455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 2. DETECCI√ìN AVANZADA DE OUTLIERS\n",
    "# ========================================\n",
    "\n",
    "def detectar_outliers_turismo(df):\n",
    "    \"\"\"\n",
    "    Detecta outliers espec√≠ficos para datos tur√≠sticos\n",
    "    \"\"\"\n",
    "    print(\"=\"*70)\n",
    "    print(\"üéØ DETECCI√ìN DE OUTLIERS - AN√ÅLISIS TUR√çSTICO\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    outliers_info = {}\n",
    "    columnas_numericas = df.select_dtypes(include=[np.number]).columns\n",
    "    \n",
    "    # Crear visualizaci√≥n de outliers\n",
    "    n_cols = 2\n",
    "    n_rows = int(np.ceil(len(columnas_numericas) / n_cols))\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 4*n_rows))\n",
    "    fig.suptitle('üéØ Detecci√≥n de Outliers por Variable', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    if n_rows == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for i, col in enumerate(columnas_numericas):\n",
    "        row = i // n_cols\n",
    "        col_idx = i % n_cols\n",
    "        \n",
    "        ax = axes[row, col_idx] if n_rows > 1 else axes[col_idx]\n",
    "        \n",
    "        # Boxplot para visualizar outliers\n",
    "        bp = ax.boxplot(df[col].dropna(), patch_artist=True)\n",
    "        bp['boxes'][0].set_facecolor('lightblue')\n",
    "        bp['boxes'][0].set_alpha(0.7)\n",
    "        \n",
    "        # Calcular estad√≠sticas de outliers\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        limite_inferior = Q1 - 1.5 * IQR\n",
    "        limite_superior = Q3 + 1.5 * IQR\n",
    "        \n",
    "        outliers_iqr = df[(df[col] < limite_inferior) | (df[col] > limite_superior)]\n",
    "        \n",
    "        # Z-Score method\n",
    "        z_scores = np.abs(stats.zscore(df[col].dropna()))\n",
    "        outliers_zscore = len(z_scores[z_scores > 2])\n",
    "        \n",
    "        # Guardar informaci√≥n\n",
    "        outliers_info[col] = {\n",
    "            'iqr_count': len(outliers_iqr),\n",
    "            'iqr_percentage': (len(outliers_iqr) / len(df)) * 100,\n",
    "            'zscore_count': outliers_zscore,\n",
    "            'limite_inf': limite_inferior,\n",
    "            'limite_sup': limite_superior,\n",
    "            'outliers_values': outliers_iqr[col].tolist() if len(outliers_iqr) < 10 else []\n",
    "        }\n",
    "        \n",
    "        ax.set_title(f'{col}\\nOutliers: {len(outliers_iqr)} ({(len(outliers_iqr)/len(df)*100):.1f}%)')\n",
    "        ax.tick_params(axis='x', rotation=45)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Ocultar subplots vac√≠os\n",
    "    for i in range(len(columnas_numericas), n_rows * n_cols):\n",
    "        row = i // n_cols\n",
    "        col_idx = i % n_cols\n",
    "        ax = axes[row, col_idx] if n_rows > 1 else axes[col_idx]\n",
    "        ax.set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Reportar outliers espec√≠ficos para turismo\n",
    "    print(\"\\nüìä RESUMEN DE OUTLIERS POR VARIABLE:\")\n",
    "    for col, info in outliers_info.items():\n",
    "        print(f\"\\n   üîç {col}:\")\n",
    "        print(f\"      ‚Ä¢ IQR Method: {info['iqr_count']} outliers ({info['iqr_percentage']:.1f}%)\")\n",
    "        print(f\"      ‚Ä¢ Z-Score Method: {info['zscore_count']} outliers\")\n",
    "        print(f\"      ‚Ä¢ Rango normal: [{info['limite_inf']:.2f}, {info['limite_sup']:.2f}]\")\n",
    "        \n",
    "        if info['outliers_values']:\n",
    "            print(f\"      ‚Ä¢ Valores outliers: {info['outliers_values'][:5]}...\")\n",
    "    \n",
    "    # An√°lisis especial para ciudades con ratings extremos\n",
    "    if 'Overall_Rating' in df.columns and 'City' in df.columns:\n",
    "        print(f\"\\nüåü AN√ÅLISIS DE RATINGS EXTREMOS:\")\n",
    "        \n",
    "        # Ciudades con ratings muy altos (posibles outliers positivos)\n",
    "        high_rating_threshold = df['Overall_Rating'].quantile(0.95)\n",
    "        ciudades_top = df[df['Overall_Rating'] >= high_rating_threshold]\n",
    "        \n",
    "        print(f\"   üìà Ciudades con rating excepcional (>= {high_rating_threshold:.1f}):\")\n",
    "        for _, city in ciudades_top.head().iterrows():\n",
    "            print(f\"      ‚Ä¢ {city['City']}: {city['Overall_Rating']:.1f}/10\")\n",
    "        \n",
    "        # Ciudades con ratings muy bajos (posibles outliers negativos)\n",
    "        low_rating_threshold = df['Overall_Rating'].quantile(0.05)\n",
    "        ciudades_bottom = df[df['Overall_Rating'] <= low_rating_threshold]\n",
    "        \n",
    "        print(f\"   üìâ Ciudades con rating bajo (<= {low_rating_threshold:.1f}):\")\n",
    "        for _, city in ciudades_bottom.head().iterrows():\n",
    "            print(f\"      ‚Ä¢ {city['City']}: {city['Overall_Rating']:.1f}/10\")\n",
    "    \n",
    "    return outliers_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4335b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 3. CREACI√ìN DE NUEVAS VARIABLES\n",
    "# ========================================\n",
    "\n",
    "def crear_variables_derivadas_turismo(df):\n",
    "    \"\"\"\n",
    "    Crea nuevas variables espec√≠ficas para an√°lisis tur√≠stico\n",
    "    \"\"\"\n",
    "    print(\"=\"*70)\n",
    "    print(\"üîÑ CREACI√ìN DE VARIABLES DERIVADAS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    df_transformado = df.copy()\n",
    "    variables_creadas = 0\n",
    "    \n",
    "    # 3.1 Categor√≠as de rating general\n",
    "    if 'Overall_Rating' in df_transformado.columns:\n",
    "        df_transformado['Rating_Category'] = pd.cut(\n",
    "            df_transformado['Overall_Rating'],\n",
    "            bins=[0, 5, 6.5, 8, 10],\n",
    "            labels=['Bajo', 'Medio', 'Alto', 'Excelente'],\n",
    "            include_lowest=True\n",
    "        )\n",
    "        variables_creadas += 1\n",
    "        print(\"   ‚úÖ 'Rating_Category' creada (Bajo/Medio/Alto/Excelente)\")\n",
    "    \n",
    "    # 3.2 √çndice clim√°tico (combinaci√≥n de temperatura y lluvia)\n",
    "    if 'Average_Temperature' in df_transformado.columns and 'Annual_Rainfall' in df_transformado.columns:\n",
    "        # Normalizar variables para el √≠ndice\n",
    "        temp_norm = (df_transformado['Average_Temperature'] - df_transformado['Average_Temperature'].min()) / \\\n",
    "                   (df_transformado['Average_Temperature'].max() - df_transformado['Average_Temperature'].min())\n",
    "        \n",
    "        # Invertir lluvia (menos lluvia = mejor clima)\n",
    "        rain_norm = 1 - ((df_transformado['Annual_Rainfall'] - df_transformado['Annual_Rainfall'].min()) / \\\n",
    "                        (df_transformado['Annual_Rainfall'].max() - df_transformado['Annual_Rainfall'].min()))\n",
    "        \n",
    "        df_transformado['Climate_Index'] = (temp_norm * 0.6 + rain_norm * 0.4) * 10\n",
    "        variables_creadas += 1\n",
    "        print(\"   ‚úÖ 'Climate_Index' creada (√≠ndice combinado clima)\")\n",
    "    \n",
    "    # 3.3 Categor√≠as de costo\n",
    "    if 'Cost_Index' in df_transformado.columns:\n",
    "        df_transformado['Cost_Category'] = pd.cut(\n",
    "            df_transformado['Cost_Index'],\n",
    "            bins=[0, 50, 75, 100, float('inf')],\n",
    "            labels=['Econ√≥mico', 'Moderado', 'Caro', 'Premium']\n",
    "        )\n",
    "        variables_creadas += 1\n",
    "        print(\"   ‚úÖ 'Cost_Category' creada (Econ√≥mico/Moderado/Caro/Premium)\")\n",
    "    \n",
    "    # 3.4 √çndice tur√≠stico compuesto (si tenemos m√∫ltiples ratings)\n",
    "    rating_columns = [col for col in df_transformado.columns if 'Rating' in col and col != 'Overall_Rating']\n",
    "    \n",
    "    if len(rating_columns) >= 3:\n",
    "        # Crear promedio ponderado de ratings espec√≠ficos\n",
    "        weights = {\n",
    "            'Attractions_Rating': 0.25,\n",
    "            'Culture_Rating': 0.20,\n",
    "            'Food_Rating': 0.20,\n",
    "            'Safety_Rating': 0.15,\n",
    "            'Shopping_Rating': 0.10,\n",
    "            'Nightlife_Rating': 0.10\n",
    "        }\n",
    "        \n",
    "        tourism_index = 0\n",
    "        weight_sum = 0\n",
    "        \n",
    "        for col in rating_columns:\n",
    "            if col in weights:\n",
    "                tourism_index += df_transformado[col] * weights[col]\n",
    "                weight_sum += weights[col]\n",
    "            else:\n",
    "                tourism_index += df_transformado[col] * 0.05  # Peso por defecto\n",
    "                weight_sum += 0.05\n",
    "        \n",
    "        df_transformado['Tourism_Index'] = tourism_index / weight_sum if weight_sum > 0 else tourism_index\n",
    "        variables_creadas += 1\n",
    "        print(\"   ‚úÖ 'Tourism_Index' creada (√≠ndice tur√≠stico compuesto)\")\n",
    "    \n",
    "    # 3.5 Clasificaci√≥n por volumen tur√≠stico\n",
    "    if 'Tourist_Volume' in df_transformado.columns:\n",
    "        # Usar percentiles para clasificar\n",
    "        p25 = df_transformado['Tourist_Volume'].quantile(0.25)\n",
    "        p50 = df_transformado['Tourist_Volume'].quantile(0.50)\n",
    "        p75 = df_transformado['Tourist_Volume'].quantile(0.75)\n",
    "        \n",
    "        df_transformado['Tourism_Volume_Category'] = pd.cut(\n",
    "            df_transformado['Tourist_Volume'],\n",
    "            bins=[0, p25, p50, p75, float('inf')],\n",
    "            labels=['Baja', 'Moderada', 'Alta', 'Masiva']\n",
    "        )\n",
    "        variables_creadas += 1\n",
    "        print(\"   ‚úÖ 'Tourism_Volume_Category' creada\")\n",
    "    \n",
    "    # 3.6 √çndice de estacionalidad (si tenemos best visit month)\n",
    "    if 'Best_Visit_Month' in df_transformado.columns:\n",
    "        # Mapear meses a estaciones (hemisferio norte por defecto)\n",
    "        season_map = {\n",
    "            12: 'Invierno', 1: 'Invierno', 2: 'Invierno',\n",
    "            3: 'Primavera', 4: 'Primavera', 5: 'Primavera',\n",
    "            6: 'Verano', 7: 'Verano', 8: 'Verano',\n",
    "            9: 'Oto√±o', 10: 'Oto√±o', 11: 'Oto√±o'\n",
    "        }\n",
    "        \n",
    "        df_transformado['Best_Season'] = df_transformado['Best_Visit_Month'].map(season_map)\n",
    "        variables_creadas += 1\n",
    "        print(\"   ‚úÖ 'Best_Season' creada (estaci√≥n √≥ptima de visita)\")\n",
    "    \n",
    "    # 3.7 Ratio precio-calidad\n",
    "    if 'Cost_Index' in df_transformado.columns and 'Overall_Rating' in df_transformado.columns:\n",
    "        # Ratio: mayor valor indica mejor relaci√≥n calidad-precio\n",
    "        df_transformado['Value_for_Money'] = df_transformado['Overall_Rating'] / (df_transformado['Cost_Index'] / 100)\n",
    "        variables_creadas += 1\n",
    "        print(\"   ‚úÖ 'Value_for_Money' creada (relaci√≥n calidad-precio)\")\n",
    "    \n",
    "    print(f\"\\nüìä RESUMEN DE TRANSFORMACI√ìN:\")\n",
    "    print(f\"   ‚Ä¢ Variables originales: {len(df.columns)}\")\n",
    "    print(f\"   ‚Ä¢ Variables nuevas creadas: {variables_creadas}\")\n",
    "    print(f\"   ‚Ä¢ Variables totales: {len(df_transformado.columns)}\")\n",
    "    \n",
    "    return df_transformado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d1580982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 4. FUNCI√ìN PRINCIPAL FASE 2\n",
    "# ========================================\n",
    "\n",
    "def main_fase2_ciudades(df):\n",
    "    \"\"\"\n",
    "    Ejecuta toda la fase 2 de limpieza para dataset tur√≠stico\n",
    "    \"\"\"\n",
    "    print(\"üöÄ INICIANDO EDA - FASE 2: LIMPIEZA Y PREPROCESAMIENTO\")\n",
    "    print(\"Dataset: Worldwide Travel Cities Ratings and Climate\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Guardar copia original para comparaci√≥n\n",
    "    df_original = df.copy()\n",
    "    \n",
    "    # 1. Limpiar datos\n",
    "    print(\"üîß PASO 1: LIMPIEZA DE DATOS\")\n",
    "    df_limpio = limpiar_datos_ciudades(df)\n",
    "    \n",
    "    # 2. Detectar outliers\n",
    "    print(\"\\nüéØ PASO 2: DETECCI√ìN DE OUTLIERS\")\n",
    "    outliers_info = detectar_outliers_turismo(df_limpio)\n",
    "    \n",
    "    # 3. Crear variables derivadas\n",
    "    print(\"\\nüîÑ PASO 3: CREACI√ìN DE VARIABLES DERIVADAS\")\n",
    "    df_final = crear_variables_derivadas_turismo(df_limpio)\n",
    "    \n",
    "    # 4. Resumen final\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"‚úÖ FASE 2 COMPLETADA EXITOSAMENTE\")\n",
    "    print(f\"üìä Dataset procesado: {df_final.shape[0]} ciudades, {df_final.shape[1]} variables\")\n",
    "    \n",
    "    # Mostrar cambios realizados\n",
    "    print(f\"\\nüìà CAMBIOS REALIZADOS:\")\n",
    "    print(f\"   ‚Ä¢ Filas: {len(df_original)} ‚Üí {len(df_final)}\")\n",
    "    print(f\"   ‚Ä¢ Columnas: {len(df_original.columns)} ‚Üí {len(df_final.columns)}\")\n",
    "    print(f\"   ‚Ä¢ Valores nulos eliminados: {df_original.isnull().sum().sum()} ‚Üí {df_final.isnull().sum().sum()}\")\n",
    "    \n",
    "    # Guardar dataset limpio\n",
    "    try:\n",
    "        df_final.to_csv('data/processed/cities_cleaned_and_transformed.csv', index=False)\n",
    "        print(f\"   ‚Ä¢ Dataset guardado: data/processed/cities_cleaned_and_transformed.csv\")\n",
    "    except:\n",
    "        print(f\"   ‚Ä¢ No se pudo guardar el dataset (directorio no existe)\")\n",
    "    \n",
    "    print(\"üìù Pr√≥ximo paso: An√°lisis exploratorio detallado\")\n",
    "    \n",
    "    return df_final, outliers_info\n",
    "\n",
    "# Ejemplo de uso\n",
    "if __name__ == \"__main__\":\n",
    "    # Aqu√≠ cargar√≠as tu df desde la fase 1\n",
    "    # df_final, outliers_info = main_fase2_ciudades(df)\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
